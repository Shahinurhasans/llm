{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b6fe0c1-931e-4194-bcfe-0716d8f75b50",
   "metadata": {},
   "source": [
    "# Youtube Video Summarization\n",
    "\n",
    "## My First Frontier LLM Project!\n",
    "\n",
    "Welcome to my first LLM-based project! The goal of this project is to leverage large language models (LLMs) to summarize YouTube videos. Currently, it only supports English transcriptions, so instead of watching the entire video, you can simply read the summary!\n",
    "\n",
    "## Important Note\n",
    "Be mindful when testing with longer videos, as they may consume significant resources and could lead to high costs on your ChatGPT bill.\n",
    "You can switch to Ollama for free usage if you're looking to reduce costs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e2a9393-7767-488e-a8bf-27c12dca35bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: youtube-transcript-api in f:\\vvi\\do_not_touch\\envs\\llms\\lib\\site-packages (1.0.1)\n",
      "Requirement already satisfied: openai in f:\\vvi\\do_not_touch\\envs\\llms\\lib\\site-packages (1.66.3)\n",
      "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in f:\\vvi\\do_not_touch\\envs\\llms\\lib\\site-packages (from youtube-transcript-api) (0.7.1)\n",
      "Requirement already satisfied: requests in f:\\vvi\\do_not_touch\\envs\\llms\\lib\\site-packages (from youtube-transcript-api) (2.32.3)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in f:\\vvi\\do_not_touch\\envs\\llms\\lib\\site-packages (from openai) (4.8.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in f:\\vvi\\do_not_touch\\envs\\llms\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in f:\\vvi\\do_not_touch\\envs\\llms\\lib\\site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in f:\\vvi\\do_not_touch\\envs\\llms\\lib\\site-packages (from openai) (0.9.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in f:\\vvi\\do_not_touch\\envs\\llms\\lib\\site-packages (from openai) (2.10.6)\n",
      "Requirement already satisfied: sniffio in f:\\vvi\\do_not_touch\\envs\\llms\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in f:\\vvi\\do_not_touch\\envs\\llms\\lib\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in f:\\vvi\\do_not_touch\\envs\\llms\\lib\\site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in f:\\vvi\\do_not_touch\\envs\\llms\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in f:\\vvi\\do_not_touch\\envs\\llms\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in f:\\vvi\\do_not_touch\\envs\\llms\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in f:\\vvi\\do_not_touch\\envs\\llms\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in f:\\vvi\\do_not_touch\\envs\\llms\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in f:\\vvi\\do_not_touch\\envs\\llms\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n",
      "Requirement already satisfied: colorama in f:\\vvi\\do_not_touch\\envs\\llms\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in f:\\vvi\\do_not_touch\\envs\\llms\\lib\\site-packages (from requests->youtube-transcript-api) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in f:\\vvi\\do_not_touch\\envs\\llms\\lib\\site-packages (from requests->youtube-transcript-api) (2.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install youtube-transcript-api openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a082ddaf-abf5-4e6c-8112-74846c768301",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "from openai import OpenAI\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "import re\n",
    "\n",
    "# If you get an error running this cell, then please head over to the troubleshooting notebook!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b87cadb-d513-4303-baee-a37b6f938e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key found and looks good so far!\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables in a file called .env\n",
    "\n",
    "load_dotenv(override=True)\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# Check the key\n",
    "\n",
    "if not api_key:\n",
    "    print(\"No API key was found - please head over to the troubleshooting notebook in this folder to identify & fix!\")\n",
    "elif not api_key.startswith(\"sk-proj-\"):\n",
    "    print(\"An API key was found, but it doesn't start sk-proj-; please check you're using the right key - see troubleshooting notebook\")\n",
    "elif api_key.strip() != api_key:\n",
    "    print(\"An API key was found, but it looks like it might have space or tab characters at the start or end - please remove them - see troubleshooting notebook\")\n",
    "else:\n",
    "    print(\"API key found and looks good so far!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "019974d9-f3ad-4a8a-b5f9-0a3719aea2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5e793b2-6775-426a-a139-4848291d0463",
   "metadata": {},
   "outputs": [],
   "source": [
    "class YoutubeVideoID:\n",
    "    def __init__(self, url):\n",
    "        self.url = url\n",
    "        self.video_id = self.extract_video_id(url)\n",
    "\n",
    "    def extract_video_id(self, url):\n",
    "        \"\"\"\n",
    "        Extracts the YouTube video ID from a given URL.\n",
    "        Supports both regular and shortened URLs.\n",
    "        \"\"\"\n",
    "        # Regular expression to match YouTube video URL and extract the video ID\n",
    "        regex = r\"(?:https?:\\/\\/)?(?:www\\.)?(?:youtube\\.com\\/(?:[^\\/\\n\\s]+\\/\\S+\\/|\\S*\\?v=)|(?:youtu\\.be\\/))([a-zA-Z0-9_-]{11})\"\n",
    "        match = re.match(regex, url)\n",
    "        \n",
    "        if match:\n",
    "            return match.group(1)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid YouTube URL\")\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"Video ID: {self.video_id}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ef960cf-6dc2-4cda-afb3-b38be12f4c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video ID: kqaMIFEz15s\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "video_url = \"https://www.youtube.com/watch?v=kqaMIFEz15s\"\n",
    "\n",
    "yt_video = YoutubeVideoID(video_url)\n",
    "print(yt_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f724be3c-bdeb-4079-b4be-f12608144484",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transcript(video_id, language='en'):\n",
    "    try:\n",
    "        # Try to get the transcript in the desired language (Indonesian by default)\n",
    "        transcript = YouTubeTranscriptApi.get_transcript(video_id, languages=[language])\n",
    "        # Join all the 'text' fields into a single string\n",
    "        return \" \".join([item['text'] for item in transcript])\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching transcript: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12e302fa-f564-4ec6-a08f-b3b3ce549396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16073\n"
     ]
    }
   ],
   "source": [
    "# Fetch transcript using the video ID\n",
    "transcript_text = get_transcript(yt_video.video_id)\n",
    "print(len(transcript_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a0750be-88a1-4e65-9cb8-a0a2f11eecdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to summarize text using ChatGPT\n",
    "def summarize_text(text):\n",
    "    try:\n",
    "        system_prompts = \"\"\"\n",
    "        You are a helpful assistant who provides concise and accurate summaries of text. Your task is to:\n",
    "        \n",
    "        - Capture the key points of the content.\n",
    "        - Keep the summary brief and easy to understand.\n",
    "        - Avoid summarizing overly lengthy texts or breaking them into excessively short summaries.\n",
    "        - Use bullet points where appropriate to enhance clarity and structure.\n",
    "        \"\"\"\n",
    "        response = openai.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompts},\n",
    "                {\"role\": \"user\", \"content\": f\"Summarize the following text:\\n{text}\"}\n",
    "            ],\n",
    "            max_tokens=200\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        print(f\"Error summarizing text: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad646bc4-a11a-4c44-b941-54befdbf9bc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "- Two years ago, the narrator discussed cybersecurity trends for 2023 and 2024, and is now predicting for 2025 and beyond.\n",
       "- A review of last year's predictions shows substantial developments:\n",
       "  - **Passkeys Adoption**: The transition from passwords to passkeys (FIDO technology) has seen significant growth, with 4.2 million passkeys saved and one in three users utilizing them.\n",
       "  - **AI Phishing**: Generative AI has improved phishing attempts, creating highly personalized and legitimate-looking emails, reducing errors that were once common in such scams.\n",
       "  - **Deepfakes**: A significant incident occurred where a deepfake impersonated a CFO in a video call, resulting in a $25 million fraud. This was noted as a concerning trend during events like the 2024 presidential election. \n",
       "\n",
       "Overall, the narrator's previous predictions about the advancement of cybersecurity threats and technologies appear to have largely materialized. - **Deepfake Incident**: A deepfake robocall featuring Joe Biden misled voters about the necessity of participating in the primary election, suggesting they could save their votes for the general election.\n",
       "  \n",
       "- **Issues with Generative AI**: \n",
       "  - Generative AI sometimes generates false information (referred to as \"hallucinations\").\n",
       "  - An example involved converting a friend's running pace from kilometers to miles, where an AI chatbot incorrectly reported a world record time before finally correcting it to a more realistic pace.\n",
       "\n",
       "- **Concerns About AI Security**:\n",
       "  - There is a growing need for cybersecurity measures to protect AI deployments, which has become a primary concern for companies.\n",
       "  - The speaker reports that securing AI is the top question from clients regarding their AI strategies.\n",
       "\n",
       "- **AI in Cybersecurity**: \n",
       "  - Predictive uses for AI in cybersecurity include developing advanced chatbots to assist analysts with accurate, fact-based responses using retrieval-augmented generation (RAG) technology The text discusses the future implications of technology and AI on cybersecurity, highlighting both positive and negative trends. Key points include:\n",
       "\n",
       "- **Advancements in Technology**: Trends in technology, particularly generative AI, are emerging in the market, aiding case management and incident tracking.\n",
       "- **Generative AI Benefits**: Generative AI can effectively summarize incidents, assisting in the transition of cases between individuals.\n",
       "- **Looking Ahead**: While past trends in technology may evolve, AI will play a significant role in shaping the future, with both advantages and disadvantages.\n",
       "- **Concerns About Shadow AI**: Unauthorized AI deployments (referred to as \"shadow AI\") pose risks, such as data leakage and operational issues within organizations.\n",
       "- **Deepfake Risks**: The growing sophistication of deepfake technology presents dangers to businesses and governments, exemplified by significant financial fraud cases.\n",
       "\n",
       "Overall, the piece emphasizes the dual nature of technological advances, particularly in AI, highlighting both their potential benefits and the serious risks they may - **Reliability of Sources**: Concerns are raised about the authenticity of information, particularly how deepfakes can mislead people, influencing beliefs.\n",
       "  \n",
       "- **Legal Implications**: The text discusses the challenges deepfakes pose in legal contexts, such as evidence in court. This could create reasonable doubt about the authenticity of evidence (e.g., whether a video shows the actual perpetrator of a crime).\n",
       "\n",
       "- **Cybersecurity Threats**: Generative AI can be exploited to write malware, making cyber attacks easier for those without technical skills. A study indicated that generative AI chatbots could generate exploit code successfully a high percentage of the time.\n",
       "\n",
       "- **Increase in Attacks**: A major online retailer reported a significant increase in cyber attacks, attributed to the misuse of generative AI technologies.\n",
       "\n",
       "- **Expanded Attack Surface**: Each new technology, including AI, increases the points of entry for cyber attacks. This includes risks associated with \"shadow AI\" and the potential for data - **Prompt Injection Concerns**: \n",
       "  - Generative AI is vulnerable to prompt injection attacks, where it is manipulated to perform unintended actions.\n",
       "  - This presents a significant security risk, as mentioned by the OWASP organization as the top attack type against large language models.\n",
       "  - There is currently a need for improved defenses against these attacks.\n",
       "\n",
       "- **Positive Use of AI in Cybersecurity**:\n",
       "  - Despite the risks, AI can be leveraged to enhance cybersecurity measures.\n",
       "  - Generative AI can assist in threat analysis and provide expert advice on potential responses to security breaches, rather than automating responses directly.\n",
       "  - This approach allows cybersecurity professionals to evaluate and choose between suggested actions.\n",
       "\n",
       "- **Quantum Computing Threats**:\n",
       "  - Quantum computers pose a future risk to cryptography, as they could potentially break current encryption methods.\n",
       "  - While quantum technology has beneficial applications, its ability to compromise encrypted messages is a significant concern that needs to be addressed, with uncertainty regarding the timeline of when - Emphasis on the urgency of transitioning to quantum-safe or post-quantum cryptographic algorithms to protect data from potential quantum computer attacks.\n",
       "- Concern over the “harvest now, decrypt later” tactic, where attackers can store data now and decrypt it later when quantum computers become powerful enough.\n",
       "- Highlighting the risks for sensitive information, especially related to nation-states that may remain classified for long periods.\n",
       "- Anticipation of organizations beginning to adopt quantum-safe cryptography projects.\n",
       "- Mention of available resources for deeper insights on the IBM Technology Channel related to these topics.\n",
       "- Invitation for readers to share their own predictions in the comments for community knowledge exchange."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def split_text(text, chunk_size=3000):\n",
    "    \"\"\"\n",
    "    Splits large text into smaller chunks based on the given chunk size.\n",
    "    Ensures that chunks end with a full stop where possible to maintain sentence integrity.\n",
    "    \n",
    "    :param text: str, the text to be split\n",
    "    :param chunk_size: int, maximum size of each chunk (default 3000 characters)\n",
    "    :return: list of str, where each str is a chunk of text\n",
    "    \"\"\"\n",
    "    chunks = []\n",
    "    while len(text) > chunk_size:\n",
    "        # Find the last full stop within or at the chunk size\n",
    "        split_point = text.rfind('.', 0, chunk_size + 1)  # +1 to include the period itself if it's at chunk_size\n",
    "        if split_point == -1:  # No period found within the chunk size\n",
    "            split_point = chunk_size\n",
    "        \n",
    "        # Append the chunk, ensuring we don't strip spaces that might be part of the sentence structure\n",
    "        chunks.append(text[:split_point + 1] if split_point != chunk_size else text[:chunk_size])\n",
    "        text = text[split_point + 1:] if split_point != chunk_size else text[chunk_size:]\n",
    "    \n",
    "    # Add the remaining text as the final chunk, only strip if there's content\n",
    "    if text:\n",
    "        chunks.append(text.strip())\n",
    "    \n",
    "    return chunks\n",
    "\n",
    "transcript_chunks = split_text(transcript_text)\n",
    "\n",
    "# Now you can summarize each chunk individually\n",
    "summaries = []\n",
    "for chunk in transcript_chunks:\n",
    "    summary = summarize_text(chunk)\n",
    "    summaries.append(summary)\n",
    "\n",
    "\n",
    "# Combine the individual summaries into one\n",
    "full_summary = \" \".join(summaries)\n",
    "display(Markdown(full_summary))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b266fdc-da31-4d79-8982-be77f03be59f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792c814d-73f8-4c1e-a0bb-b654b40e4d8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
